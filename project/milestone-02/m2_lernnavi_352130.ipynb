{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09db7cae",
   "metadata": {
    "id": "457a6a91-117e-41b3-be96-ffa6ac9d92e7"
   },
   "source": [
    "# M2 | Exploration Notebook\n",
    "\n",
    "In this notebook, you will do a first exploration of the data set that you will use for your project. One part of this exploration is guided, i.e. we will ask you to solve specific questions (task 1-3). The other part is open, i.e. we will ask you to come up with your own exploration ideas (task 4). \n",
    "\n",
    "Please upload your solved notebook to Moodle (under Milestone 2 Submission)adding your SCIPER number in title, example: m2-lernnavi-456392.ipynb\n",
    "\n",
    "\n",
    "## Brief overview of Lernnavi\n",
    "[Lernnavi](https://www.lernnavi.ch) is an instrument for promoting part of the basic technical study skills in German and mathematics.\n",
    "\n",
    "\n",
    "For the guided part of the exploration we will focus on the three main tables:\n",
    "* *users*: demographic information of users.\n",
    "* *events*: events done by the users in the platform.\n",
    "* *transactions*: question and answer solved by user.\n",
    "\n",
    "### Users\n",
    "* user_id: unique identifier of user in database.\n",
    "* gender: only three values: M male, F female or missing (star). \n",
    "* canton: swiss canton.\n",
    "* class_level: school year in swiss system.\n",
    "* study: boolean variable. True if the student participated in the study.\n",
    "* class_id: identifier of student’s class (only for the students in the experiment)\n",
    "\n",
    "\n",
    "### Events\n",
    "* event_id: unique identifier of event in database.\n",
    "* user_id: user who peformed the event.\n",
    "* event_date: timestamp of event.\n",
    "* category: classification of action (task, general, statistics, etc).\n",
    "* action: type of action performed.\n",
    "* event_type: whether the students viewed or clicked in the event.\n",
    "* transaction_token: used to link to transactions table.\n",
    "* tracking_data: optional content associated to this event (e.g., the new points mastered for a topic).\n",
    "* session_id: session during which the event took place.\n",
    "* topic_id: the topics represent the taxonomy of categories shown in the Deutsch and Math dashboard. See topics_translated table.\n",
    "* session_closed: whether the session has been finished (1: finished; 0: not finished).\n",
    "* session_type: whether the session is a learn or level check (1: learn; 2: level check).\n",
    "* session_accepted: whether the user finally accepted the result of the session (1: accepted; 0: refused).\n",
    "\n",
    "### Transactions\n",
    "* transaction_id: unique identifier of transaction in database.\n",
    "* transaction_token: used to link to events table.\n",
    "* user_id: user who performed the transaction.\n",
    "* document_id: document that was answered in transaction.\n",
    "* document_version: version of document that was answered.\n",
    "* evaluation: whether the user answered correctly or not. It is possible that it was only partially right. \n",
    "* input: answer the user gave.\n",
    "* start_time: timestamp of when the user started answering.\n",
    "* commit_time: timestamp of when the user submitted the answer.\n",
    "* user_agent: the browser that the user used.\n",
    "* solution: solution to question.\n",
    "* type: type of question that was answered. \n",
    "* session_id: session during which the event took place.\n",
    "* topic_id: the topics represent the taxonomy of categories shown in the Deutsch and Math dashboard. See topics_translated table.\n",
    "* session_closed: whether the session has been finished (1: finished; 0: not finished).\n",
    "* session_type: whether the session is a learn or level check (1: learn; 2: level check).\n",
    "* session_accepted: whether the user finally accepted the result of the session (1: accepted; 0: refused).\n",
    "* challenge: (boolean) whether the transaction was part of a challenge or not. Professors can create challenges containing different documents\n",
    "* challenge_id: unique identifier of challenges. The same challenge can be done by multiple students. The pre-test and post-test in the study were designed like challenges.\n",
    "* challenge_order: within the challenge, the order of the questions. The order matters because sometimes the questions were adapted depending on the student’s knowledge.\n",
    "* challenge_name: name given to the challenges. \n",
    "\n",
    "## Useful Metadata Files\n",
    "* [Data description](https://docs.google.com/document/d/1NPFNwi79JddrxZM-CpltH5nHro5btHRSNnYcAGj7Y0A/edit?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1e6d4",
   "metadata": {
    "id": "2b10fd14-a60b-4de9-b217-bbaf68dac01c"
   },
   "outputs": [],
   "source": [
    "# Import the tables of the data set as dataframes.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = '../data' #You many change the directory\n",
    "\n",
    "users = pd.read_csv('{}/users.csv.gz'.format(DATA_DIR))\n",
    "events = pd.read_csv('{}/events.csv.gz'.format(DATA_DIR))\n",
    "transactions = pd.read_csv('{}/transactions.csv.gz'.format(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19642d1f",
   "metadata": {
    "id": "75b4f5fc-4526-4c00-8045-393cd36a2de6"
   },
   "source": [
    "## Task 1: Simple Statistics\n",
    "\n",
    "In this task you are asked to do a first coarse exploration of the data set, using simple statistics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae79c58",
   "metadata": {
    "id": "811d42c0-6f94-436e-b2da-232363fedace"
   },
   "source": [
    "#### a) How many distinct participants do we have in the data set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9a0b3",
   "metadata": {
    "id": "3935e6ea-982b-4d88-81c1-406f6d8040e8"
   },
   "outputs": [],
   "source": [
    "print('Number of unique user_ids:', users['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06974b3",
   "metadata": {
    "id": "afa67951-aed8-4709-a935-9918d80ede84"
   },
   "source": [
    "#### b) How many transactions were done per user? Please provide a visualization and discuss the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c1d35",
   "metadata": {
    "id": "adefdeef-23d3-4feb-9c6f-6a3dd441acf2"
   },
   "outputs": [],
   "source": [
    "# Group the transaction_ids by the user_ids, which counts up all transactions per user\n",
    "transactions_per_user = transactions.groupby(['user_id'])['transaction_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f117c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a histogram, but we limit it to 1500 transactions in order for better visualization\n",
    "transactions_per_user.hist(bins=200)\n",
    "plt.xlim(0, 1500)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of transactions')\n",
    "plt.title('Number of transactions for every user')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02967bb",
   "metadata": {
    "id": "zkDaH4M_a3vR"
   },
   "source": [
    "The distribution looks something like an exponential, which becomes visible when ignoring outliers. These are likely users that use the application a lot, with one person being at 15982 transactions; more than 8 times more than any other user. It could be interesting to investigate this user. The (what seems to be an exponential) decay in the histogram motivates my choice for the distribution, as well as then intuition that less and less people will have more time in the app (implying transactions) as time goes on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaf13e",
   "metadata": {
    "id": "b14fea28-8507-497d-9990-9eb2fefd18c0"
   },
   "source": [
    "#### c) Which are the 10 most popular event actions? Please provide a visualization of the frequency of the top 10 event actions.\n",
    "\n",
    "Hint: See actions in table events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6b8f0",
   "metadata": {
    "id": "e991ecba"
   },
   "outputs": [],
   "source": [
    "# This code groups the 10 largest actions\n",
    "number_of_largest_cols = 10\n",
    "num_events_per_action = events.groupby(['action'])['event_id'].nunique().nlargest(number_of_largest_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163923ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a bar chart to display them\n",
    "num_events_per_action.plot.bar()\n",
    "plt.ylabel('Number of Events')\n",
    "plt.xlabel('Action ID')\n",
    "plt.title('Number of Events for the Top 10 Actions IDs')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb7fad",
   "metadata": {
    "id": "0e7818a8-e4bc-499c-8683-28b7045e59a2"
   },
   "source": [
    "The most common action seems to be PAGE_VISIT, which makes sense, as it is required for almost anything in the application. REVIEW_TASK seems to be second, most likely since there are multiple questions and a user has to click between them after doing a quick. This triggers this event each time. However, what is interesting is that SUBMIT_ANSWER is third highest. It seems like users are engaged with the application, and utilize the quiz instead of just skimming through. The dashboard (NAVIGATE_DASHBOARD) is also quite popular, since the users interact with different elements in the quiz. Students also seem to look at open-ended feedback a little more than closed-ended feedback, them being the top 9 and 10 most popular actions.\n",
    "\n",
    "There is one weird thing, since the metadata mentions that SUBMIT_ANSWER should happen after VIEW_QUESTION and before NEXT. However, there seems to be less VIEW_QUESTION than SUBMIT_ANSWER, which is quite strange. I do not have a direct explanation for thism but it seems like something is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f2e9b",
   "metadata": {
    "id": "55dd2ced-e567-4b23-8795-cce5132cfdad"
   },
   "source": [
    "## Task 2: Static Analysis\n",
    "\n",
    "In this second task, you will do a univariate an multivariate exploration of some aggregated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093f4a1",
   "metadata": {
    "id": "c6278746-ebab-45e7-8312-36f6cc1d4e36"
   },
   "source": [
    "#### a) Build a data frame containing one row per user:\n",
    "\n",
    "``[user_id, gender, num_events, num_questions, percentage_correct, num_reading]``\n",
    "\n",
    "\n",
    "The features are defined as follows:\n",
    "\n",
    "- **num_questions**: total number of questions the student answered (hint: action event = submit answer)\n",
    "\n",
    "- **num_events**: total number of events of the student (hint: in events table)  \n",
    "\n",
    "- **percentage_correct**: number of correct answers/total number of answers (hint: evaluation = correct). If desired, you may assign a weight of 0.5 to partially correct answers. \n",
    "\n",
    "- **num_reading**: total number of theory reading events  (hint: action event = go to theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9135c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to count the number of occurrences of a string in a pandas Series\n",
    "def cnt_column(series, col_name):\n",
    "    return (series == col_name).sum()\n",
    "\n",
    "# We first collect the gender and user_id\n",
    "new_df_1 = users[['user_id', 'gender']].set_index('user_id')\n",
    "\n",
    "# We then collect the number of questions by counting the number of \"SUBMIT_ANSWER\" actions per user\n",
    "new_df_2 = events.groupby(['user_id'])['action'].apply(lambda x: cnt_column(x, 'SUBMIT_ANSWER')).reset_index(name='num_questions')\n",
    "new_df_2 = new_df_2.set_index('user_id')\n",
    "\n",
    "# Here, we count the number of events of each user\n",
    "new_df_3 = events.groupby(['user_id'])['event_id'].nunique().reset_index('user_id')\n",
    "new_df_3 = new_df_3.rename(columns={'event_id':'num_events'}).set_index('user_id')\n",
    "\n",
    "# This dictionary assigns partial points for partially correctly answered questions\n",
    "point_assignments = {\n",
    "    'WRONG': 0,\n",
    "    'PARTIAL': 0.5,\n",
    "    'CORRECT': 1\n",
    "}\n",
    "\n",
    "# We now create a new temporary column that does this point mapping\n",
    "transactions['point_evaluation'] = transactions['evaluation'].map(point_assignments)\n",
    "\n",
    "# Now we create the average percentage of correct answers by averaging the number of points per user\n",
    "# We decide to ignore NaNs in the computation by default\n",
    "new_df_4 = transactions.groupby(['user_id'])['point_evaluation'].mean() * 100\n",
    "new_df_4 = new_df_4.reset_index('user_id').rename(columns={'point_evaluation':'percentage_correct'}).set_index('user_id')\n",
    "\n",
    "# Finally, we compute the number of readings by counting the amount of \"GO_TO_THEORY\" per user\n",
    "new_df_5 = events.groupby(['user_id'])['action'].apply(lambda x: cnt_column(x, 'GO_TO_THEORY')).reset_index(name='num_reading')\n",
    "new_df_5 = new_df_5.set_index('user_id')\n",
    "\n",
    "# To create the full dataframe, we concatenate those components\n",
    "new_df = pd.concat([new_df_1, new_df_3, new_df_2, new_df_4, new_df_5], axis=1, join='inner').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There might be NaNs, coming from entries that might not have existed when creating the dataframe above, but that's okay\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30f44c",
   "metadata": {
    "id": "c7648e7d-45ff-40ef-8fc9-ccfba1ba7229"
   },
   "source": [
    "b) Perform a univariate analysis (including descriptive statistics and visualizations) for the five features (gender, num_events, num_questions, percentage_correct, num_reading) of your dataframe. Please check the lecture slides regarding information on how to perform a univariate analysis for categorical and numerical features. Discuss your results: how are the features distributed? Are there any anomalities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script just creates some plots\n",
    "indexed_df = new_df.set_index('user_id')\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, constrained_layout=True)\n",
    "fig.suptitle('Distribution Plots of Features')\n",
    "\n",
    "indexed_df['gender'].value_counts(dropna=False).plot.bar(ax=ax1)\n",
    "ax1.set_title('Bar Chart of Gender Counts', fontsize=10)\n",
    "ax1.set_xlabel('Gender')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "# We limit the histogram to 2000, since the plot would get congested with outliers\n",
    "indexed_df['num_events'].hist(ax=ax2, bins=100)\n",
    "ax2.set_xlim(0, 2000)\n",
    "ax2.set_title('Histogram of Event Counts', fontsize=10)\n",
    "ax2.set_xlabel('Number of Events')\n",
    "ax2.set_ylabel('Count')\n",
    "\n",
    "# We limit the histogram to 1000, since the plot would get congested with outliers\n",
    "indexed_df['num_questions'].hist(ax=ax3, bins=20)\n",
    "ax3.set_xlim(0, 1000)\n",
    "ax3.set_title('Histogram of Questions Counts', fontsize=10)\n",
    "ax3.set_xlabel('Number of Questions')\n",
    "ax3.set_ylabel('Count')\n",
    "\n",
    "indexed_df['percentage_correct'].hist(ax=ax4, bins=20)\n",
    "ax4.set_title('Histogram of Correct Counts', fontsize=10)\n",
    "ax4.set_xlabel('Percentage Correct')\n",
    "ax4.set_ylabel('Count')\n",
    "\n",
    "# We limit the histogram to 50, since the plot would get congested with outliers\n",
    "indexed_df['num_reading'].hist(ax=ax5, bins=500)\n",
    "ax5.set_xlim(0, 50)\n",
    "ax5.set_title('Histogram of Reading Counts', fontsize=10)\n",
    "ax5.set_xlabel('Number of Readings')\n",
    "ax5.set_ylabel('Count')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# We create some boxplots to show outliers and (kind of) get an idea of the distributions\n",
    "# They are meant to be ugly, and just have to show information about outliers\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, constrained_layout=True)\n",
    "fig.suptitle('Box Plots of Features (Ugly)')\n",
    "\n",
    "indexed_df.boxplot(column=['num_events'], ax=ax1)\n",
    "ax1.set_title('Box Plot of No. Events', fontsize=10)\n",
    "ax1.set_ylabel('Number of Events')\n",
    "\n",
    "indexed_df.boxplot(column=['num_questions'], ax=ax2)\n",
    "ax2.set_title('Box Plot of No. Questions', fontsize=10)\n",
    "ax2.set_ylabel('Number of Questions')\n",
    "\n",
    "indexed_df.boxplot(column=['percentage_correct'], ax=ax3)\n",
    "ax3.set_title('Box Plot of Percentage Correct', fontsize=10)\n",
    "ax3.set_ylabel('Percentage Correct')\n",
    "\n",
    "indexed_df.boxplot(column=['num_reading'], ax=ax4)\n",
    "ax4.set_title('Box Plot of No. Readings', fontsize=10)\n",
    "ax4.set_ylabel('Number of Readings')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Compute Descriptive Statistics\n",
    "# Partially taken from tutorial 02\n",
    "\n",
    "numerical = indexed_df.describe(include=['float64', 'int64'])\n",
    "categorical = indexed_df.describe(include=['object'])\n",
    "stats = pd.concat([numerical, categorical])\n",
    "missing_counts = indexed_df.isnull().sum(axis = 0)\n",
    "stats.loc['missing_values'] = missing_counts\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043655f",
   "metadata": {
    "id": "da9e7a90-47b5-4c5c-8d3f-10e8c8078009"
   },
   "source": [
    "Let's start with the gender of the users. There seem to be more users who registered as females than males. Furthermore, a small percentage of the users also identifies as neither. However, there are just as many users who do not report having any gender. There are no clear anomalies for this column. \n",
    "\n",
    "The second feature, which is the number of events for each user, seems to be exponentially distributed from the histogram. Furthermore, from the description and boxplot of the feature, there do appear to be some outliers. The largest, as previously mentioned, having over 16000 events. It would be interesting to investigate this user.\n",
    "\n",
    "The third feature, which is the number of questions for each user, also seems to be exponentially distributed. From the boxplot and description of this feature, there are also some outliers, but these are not of the same magnitude as the one of the number of events. These are likely just very active users, but this group could also be interesting to investigate.\n",
    "\n",
    "The fourth feature, which is the overall percentage correct, could represent a normal distribution, with the values truncated between 0 and 100. This truncation explains the small anomalies (spikes) at 0 and 100, because the worst and the best users are given the same score at those points. There are also some missing values, which indicates that some users may not have have attempted any questions.\n",
    "\n",
    "The last feature is the number of readings per user. This again seems to follow an exponential distribution, with some users that read a lot. However, it is also clear that one user had 3000 readings, which is an incredible amount more than the median of 75th percentile of 6! There are also a few more users that have around 1500 to 2000 readings, which is also significantly more than the majority of users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b077d19",
   "metadata": {
    "id": "e5d52cd8-9927-401b-a3c3-a4ab2e46b445"
   },
   "source": [
    "c) Come up with two additional features on your own and add them to the dataframe. Please provide an explanation/description of your features as well as an argument/hypothesis of why you think these features are interesting to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24b09a",
   "metadata": {
    "id": "0b374606-91f5-45b0-bb31-03d494fa5c69"
   },
   "outputs": [],
   "source": [
    "transactions['minutes_answer_time'] = pd.to_datetime(transactions['commit_time']) - pd.to_datetime(transactions['start_time'])\n",
    "transactions['minutes_answer_time'] = transactions['minutes_answer_time'].dt.total_seconds() / 60\n",
    "\n",
    "answer_time_feature = transactions.groupby(['user_id'])['minutes_answer_time'].mean()\n",
    "\n",
    "percentage_sessions_finished = transactions.groupby(['user_id'])['session_closed'].mean() * 100\n",
    "\n",
    "own_features_df = new_df.set_index('user_id')\n",
    "own_features_df = pd.concat([own_features_df, answer_time_feature, percentage_sessions_finished], axis=1, join='inner').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29beaa38",
   "metadata": {
    "id": "6ae3bd87-8ca4-47a2-afc5-604e6ca53621"
   },
   "source": [
    "I have added the following two features to the dataframe:\n",
    "\n",
    "- The average amount of minutes it takes to answer a question for each user\n",
    "\n",
    "This feature seems interesting to look into, because it gives rise to different types of users. For example, maybe users that on average spend more time on questions have a higher percentage of answers correct.\n",
    "\n",
    "- The percentage of closed sessions for each user\n",
    "\n",
    "This will give rise to the number of sessions that have been completed by the user. It could be interesting to see whether users usually finish sessions, or maybe look at correlations between this feature and the behaviour on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8737e0",
   "metadata": {
    "id": "be9b49ce-5fb6-4b95-9b64-8a6648e42474"
   },
   "source": [
    "d) Perform a univariate analysis of your features (including descriptive statistics and visualization). What can you observe? Do the results confirm your hypotheses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bb985",
   "metadata": {
    "id": "bf5136a1-4715-4bd6-a94a-1998ffb2dcc7"
   },
   "outputs": [],
   "source": [
    "indexed_own_features_df = own_features_df.set_index('user_id')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True)\n",
    "fig.suptitle('Distribution Plots of Features')\n",
    "\n",
    "# For plotting, we limit up to 10 minutes on average and create a bin for each 30 second interval\n",
    "indexed_own_features_df[indexed_own_features_df['minutes_answer_time'] < 10]['minutes_answer_time'].hist(ax=ax1, bins=20)\n",
    "ax1.set_title('Histogram of the Average Answer Time', fontsize=10)\n",
    "ax1.set_xlabel('Average Answer Time (Minutes)')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "indexed_own_features_df['session_closed'].hist(ax=ax2, bins=20)\n",
    "ax2.set_title('Histogram of Percentage of Closed Sessions', fontsize=10)\n",
    "ax2.set_xlabel('Number of Session Closed')\n",
    "ax2.set_ylabel('Count')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True)\n",
    "fig.suptitle('Box Plots of Features (Ugly)')\n",
    "\n",
    "indexed_own_features_df.boxplot(column=['minutes_answer_time'], ax=ax1)\n",
    "ax1.set_title('Box Plot of No. Events', fontsize=10)\n",
    "ax1.set_ylabel('Number of Events')\n",
    "\n",
    "indexed_own_features_df.boxplot(column=['session_closed'], ax=ax2)\n",
    "ax2.set_title('Box Plot of No. Questions', fontsize=10)\n",
    "ax2.set_ylabel('Number of Questions')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Compute Descriptive Statistics\n",
    "# Partially taken from tutorial 02\n",
    "\n",
    "stats = indexed_own_features_df[['minutes_answer_time', 'session_closed']].describe(include=['float64', 'int64'])\n",
    "missing_counts = indexed_own_features_df[['minutes_answer_time', 'session_closed']].isnull().sum(axis = 0)\n",
    "stats.loc['missing_values'] = missing_counts\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924cc499",
   "metadata": {
    "id": "791e6635-e2ef-4790-b585-a8907123bed8"
   },
   "source": [
    "The histogram of the feature describing the average answer time for each user is quite interesting. When looking at bins that each represent one minute, the histogram again looks exponential. However, when sizing down on the bin sizes, for example having it be 30 seconds per bin, there is a bit of a structure that could represent something like a log-normal distribution. For example, few users have an average answer time of under 30 seconds. The median average answer time is about 1.8 minutes. However, there are some large anomalies in the data, as can be seem from the boxplot and the descriptive statistics. The maximum value is about 462673 minutes, which should definitely be investigated.\n",
    "\n",
    "For the percentage of closed sessions, the distribution seems to represent some mirrored (in the x-axis) truncated exponential distribution. The exponential distribution could be obtained by changing the feature to the percentage of open sessions. The values between constrainted to between 0 and 100% explains why there are many at 0 From the boxplot and description, there do not seem to be many outliers, but just these users that don't have any closed session. There are also quite some missing values, indicating quite some NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b81679",
   "metadata": {
    "id": "1596debf-793b-4d94-a0eb-4fc42a1f962d"
   },
   "source": [
    "e) Perform a multivariate analysis for two pairs of features of your choice. Please provide a metric and a visualization for both pairs. Please discuss: why did you choose these two pairs? What was your hypothesis? Do the results confirm your hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe74ad",
   "metadata": {
    "id": "9b5947ca-1c39-4aec-8fa9-22dba757ef27"
   },
   "outputs": [],
   "source": [
    "filtered_df = own_features_df[own_features_df['num_reading'] < 200]\n",
    "\n",
    "print('Correlation:', filtered_df['num_reading'].corr(filtered_df['percentage_correct']))\n",
    "\n",
    "group = filtered_df.groupby('num_reading').agg({'percentage_correct': 'median'})\n",
    "\n",
    "plt.scatter(filtered_df['num_reading'], filtered_df['percentage_correct'])\n",
    "plt.plot(group.index, group['percentage_correct'], color='red', label='Median Percentage of Answers Correct')\n",
    "plt.legend()\n",
    "plt.title('The Number of Reading Events and Percentage of Answers Correct for each User')\n",
    "plt.xlabel('The Number of Reading Events')\n",
    "plt.ylabel('The Percentage of Answers Correct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a0ed",
   "metadata": {
    "id": "9c9e9e56-f589-49d4-8cd4-07855bc6c5c0"
   },
   "source": [
    "I chose to create a multivariate analysis for the variables \"num_reading\" and \"percentage_correct\", in order to see if there is some relationship between them. I hoped to see that users with a higher number of readings have a higher average percentage of correct answers. I first created a scatterplot, which had too many datapoints to be interpretable. From the scatterplot alone, it could seem that there is a smaller amount of people with a lower score. However, since there are likely many more users that read fewer events, this can't be made out from the plot.  I only included up to 200 reading numbers to make the plot more readable, and since that is well beyond the 75th percentile.\n",
    "\n",
    "For this reason, I compute the correlation, which is incredibly low, indicating little to no linear relationship between the variables. Then, I plotted the median of the percentage of correct answers for each number of readings. While there is much more certainty for smaller values (since there are many datapoints), there does not seem to be an increase in the median percentage of correct answers for a larger number of readings. However, it is important to note that the variance for more number of readings is also much larger. Hence, the results do not seem to support my hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dfd07",
   "metadata": {
    "id": "62ef2063-f2b2-4a0b-92a6-1e03e9e6e548"
   },
   "source": [
    "# Task 3: Time-Series Analysis\n",
    "\n",
    "In the last task, you will perform a time-series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5e7ad",
   "metadata": {
    "id": "1a986033-693c-4db0-8b27-c638b4bf6248"
   },
   "source": [
    "\n",
    "#### a) Build a data frame containing one row per user per week:\n",
    "\n",
    "``[user_id, week, num_events, num_questions, percentage_correct, num_reading]``\n",
    "\n",
    "\n",
    "The features are defined as follows:\n",
    "\n",
    "- **num_questions**: total number of questions the student answered **per week**(hint: action event = submit answer).\n",
    "\n",
    "- **num_events**: total number of events of the student per week.\n",
    "\n",
    "- **percentage_correct**: number of correct answers/total number of answers  **per week** (hint: evaluation = correct). If desired, you may assign a weight of 0.5 to partially correct answers.\n",
    "\n",
    "- **num_reading**: total number of theory reading events **per week** (hint: action event = go to theory).\n",
    "\n",
    "Where week 0 is the first week the specific user solved a task in the platform, i.e., the user's earliest entry in the transactions table.\n",
    "\n",
    "Hint: You may extract the week of the year (dt.week) from the timestamps.\n",
    "\n",
    "Hint 2: Be mindful that week 1 in 2022 is a different week from week 1 in 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10672e21",
   "metadata": {
    "id": "549820bd-d886-433f-8055-52f40e3381ad"
   },
   "source": [
    "You can limit the number of weeks to 10, i.e. for each user we just look at the first 10 weeks of data.\n",
    "You may change and justify your choice for the number of weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0307d32",
   "metadata": {
    "id": "a92e54ac-3990-4d97-bd57-75c81534b36d"
   },
   "outputs": [],
   "source": [
    "def cnt_column(series, col_name):\n",
    "    return (series == col_name).sum()\n",
    "\n",
    "# Create the week columns in both dataframes\n",
    "transactions['start_time'] = pd.to_datetime(transactions['start_time'])\n",
    "events['event_date'] = pd.to_datetime(events['event_date'])\n",
    "\n",
    "# Find the first transaction for each user\n",
    "first_transaction_times = transactions.groupby('user_id')['start_time'].min()\n",
    "\n",
    "# Then add this first transaction as a column to both dataframes\n",
    "# Afterwards, we compute the number of weeks from a certain transaction using the difference between them \n",
    "transaction_with_week = transactions.merge(first_transaction_times, on='user_id', suffixes=['', '_min'])\n",
    "transaction_with_week['week'] = (transaction_with_week['start_time'] - transaction_with_week['start_time_min']).dt.days // 7\n",
    "\n",
    "events_with_week = events.merge(first_transaction_times, on='user_id', suffixes=['', '_min'])\n",
    "events_with_week['week'] = (events_with_week['event_date'] - events_with_week['start_time']).dt.days // 7\n",
    "\n",
    "# Now we create the statistics\n",
    "\n",
    "WEEK_LIMIT = 10\n",
    "transaction_with_week = transaction_with_week[(0 <= transaction_with_week['week']) & (transaction_with_week['week'] < WEEK_LIMIT)]\n",
    "events_with_week = events_with_week[(0 <= events_with_week['week']) & (events_with_week['week'] < WEEK_LIMIT)]\n",
    "\n",
    "ts_df_1 = events_with_week.groupby(['user_id', 'week'])['action'].apply(lambda x: cnt_column(x, 'SUBMIT_ANSWER'))\n",
    "ts_df_1 = ts_df_1.rename('num_questions')\n",
    "\n",
    "ts_df_2 = events_with_week.groupby(['user_id', 'week'])['event_id'].nunique()\n",
    "\n",
    "point_assignments = {\n",
    "    'WRONG': 0,\n",
    "    'PARTIAL': 0.5,\n",
    "    'CORRECT': 1\n",
    "}\n",
    "\n",
    "transaction_with_week['point_evaluation'] = transaction_with_week['evaluation'].map(point_assignments)\n",
    "\n",
    "# We decide to ignore NaNs in the computation by default\n",
    "ts_df_3 = transaction_with_week.groupby(['user_id', 'week'])['point_evaluation'].mean() * 100\n",
    "\n",
    "ts_df_4 = events_with_week.groupby(['user_id', 'week'])['action'].apply(lambda x: cnt_column(x, 'GO_TO_THEORY'))\n",
    "\n",
    "ts_df = pd.concat([ts_df_1, ts_df_2, ts_df_3, ts_df_4], axis=1).reset_index()\n",
    "ts_df = ts_df.rename(columns={\n",
    "    'event_id': 'num_events', \n",
    "    'point_evaluation': 'percentage_correct',\n",
    "    'action': 'num_reading'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c868a7f",
   "metadata": {
    "id": "1d045819-a60e-4bdf-bdab-f09fa53c823a"
   },
   "source": [
    "#### b) Select two features and analyze their behavior over time. Please provide a hypothesis and visualization for both features. For ideas on how to perform a time series exploration, please check the lecture slides and notebook. Discuss your results: what do you observe? Do the results confirm your hypotheses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(x=\"week\", y=\"num_events\", data=ts_df, estimator=np.median)\n",
    "plt.title('Lineplot of the median number of events over weeks, with 95% confidence bounds')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Readings')\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(x=\"week\", y=\"num_questions\", data=ts_df, estimator=np.median)\n",
    "plt.title('Lineplot of the median number of questions answered over weeks, with 95% confidence bounds')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Questions Answered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7878e",
   "metadata": {
    "id": "3ccb6bf8-2d6b-4a53-a4bb-6784c671fec4"
   },
   "source": [
    "I selected the features \"num_events\" and \"num_questions\" to gain insights into how users utilize the application over the first 10 weeks that they use it. I have three hypotheses:\n",
    "\n",
    "1. The median number of readings will decline as the number of weeks increase\n",
    "2. The median number of questions answered will decline as the number of weeks increase\n",
    "3. The trends of the number of readings and the number of questions will be quite similar over the weeks\n",
    "\n",
    "The first and second hypothesis aim to test whether users will read fewer articles and answer fewer questions peer week as the period of them using the application increases. Finally, the third hypothesis aims to see whether the behaviour of the users for answering questions will differ from the behaviour of readings.\n",
    "\n",
    "It is important to note that I used the median as an estimator in these plots, because it is more robust to outliers like the ones we observed previously. From the first and second plot, a gradual decline in the median number of readings, and a gradual decline in the median number of answered questions is observed. It seems that users answer the most questions and read the most articles in the first week. Afterwards, they seem to use it less but kind of stabilize (with emphasis on kind of). This confirms my first and second hypothesis. Regarding the third hypothesis, the trends between the two features seem to be quite similar, but with more absolute variability in the number of readings. This might indicate that users utilize both features less, instead of preferring one to the other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85acad",
   "metadata": {
    "id": "_s7rWpaLfZGt"
   },
   "source": [
    "# Task 4: Creative extension \n",
    "\n",
    "Please provide **one** new hypothesis you would like to explore with the data and provide a visualization for it. Discuss your results: what do you observe? Do the results confirm your hypotheses?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082f6ae",
   "metadata": {
    "id": "3-Wtdj4KfdY_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df = own_features_df[own_features_df['minutes_answer_time'] < 25]\n",
    "\n",
    "print('Correlation:', filtered_df['minutes_answer_time'].corr(filtered_df['percentage_correct']))\n",
    "\n",
    "p = sns.jointplot(x=\"minutes_answer_time\", y=\"percentage_correct\", data=filtered_df, kind=\"reg\", line_kws={\"color\": \"red\"})\n",
    "p.fig.suptitle('Joint distribution plot of the average duration (minutes) to answer a question\\n and the average' \n",
    "          + 'percentage of correct answers for each user')\n",
    "p.set_axis_labels('Average duration (minutes) per answer', 'Average percentage of correct answers', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10105d",
   "metadata": {
    "id": "yTT8SklBgGxN"
   },
   "source": [
    "I added a feature which measures the average time to answer a question for each user. My hypothesis is now that a larger time it takes to answer questions results in a higher average percentage of correct answers.\n",
    "\n",
    "I first created a joint distribution plot of the two variables. I limited the average minutes per answer to 25, since this already covers the majority of the users. Then, I fitted a regression line through the data, and with that, computed the correlation between the variables. Like in task 2d, there are many more users with a smaller average duration per answer. This makes the plot seem like there might be a trend, but in reality, the regression model and correlation indicate the opposite. Hence, again, the analysis does not seem to support my hypothesis."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2-lernnavi-sciper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
